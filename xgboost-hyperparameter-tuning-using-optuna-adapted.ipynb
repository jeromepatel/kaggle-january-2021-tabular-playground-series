{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna: A hyperparameter optimization framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *In This Kernel I will use the amazing **Optuna** to find the best hyparameters of our models*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, Optuna is an automatic hyperparameter ptimization software framework, particularly designed for machine learning. It features an imperative, define-by-run style user API. The code written with Optuna enjoys high modularity, and the user of Optuna can dynamically construct the search spaces for the hyperparameters.** \n",
    "* To learn more about Optuna check this [link](https://optuna.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Concepts\n",
    "So, We use the terms study and trial as follows:\n",
    "* Study: optimization based on an objective function\n",
    "* Trial: a single execution of the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install optuna \n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test  = pd.read_csv('test.csv')\n",
    "#sub = pd.read_csv('../input/tabular-playground-series-jan-2021/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.670390</td>\n",
       "      <td>0.811300</td>\n",
       "      <td>0.643968</td>\n",
       "      <td>0.291791</td>\n",
       "      <td>0.284117</td>\n",
       "      <td>0.855953</td>\n",
       "      <td>0.890700</td>\n",
       "      <td>0.285542</td>\n",
       "      <td>0.558245</td>\n",
       "      <td>0.779418</td>\n",
       "      <td>0.921832</td>\n",
       "      <td>0.866772</td>\n",
       "      <td>0.878733</td>\n",
       "      <td>0.305411</td>\n",
       "      <td>7.243043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.388053</td>\n",
       "      <td>0.621104</td>\n",
       "      <td>0.686102</td>\n",
       "      <td>0.501149</td>\n",
       "      <td>0.643790</td>\n",
       "      <td>0.449805</td>\n",
       "      <td>0.510824</td>\n",
       "      <td>0.580748</td>\n",
       "      <td>0.418335</td>\n",
       "      <td>0.432632</td>\n",
       "      <td>0.439872</td>\n",
       "      <td>0.434971</td>\n",
       "      <td>0.369957</td>\n",
       "      <td>0.369484</td>\n",
       "      <td>8.203331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.834950</td>\n",
       "      <td>0.227436</td>\n",
       "      <td>0.301584</td>\n",
       "      <td>0.293408</td>\n",
       "      <td>0.606839</td>\n",
       "      <td>0.829175</td>\n",
       "      <td>0.506143</td>\n",
       "      <td>0.558771</td>\n",
       "      <td>0.587603</td>\n",
       "      <td>0.823312</td>\n",
       "      <td>0.567007</td>\n",
       "      <td>0.677708</td>\n",
       "      <td>0.882938</td>\n",
       "      <td>0.303047</td>\n",
       "      <td>7.776091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.820708</td>\n",
       "      <td>0.160155</td>\n",
       "      <td>0.546887</td>\n",
       "      <td>0.726104</td>\n",
       "      <td>0.282444</td>\n",
       "      <td>0.785108</td>\n",
       "      <td>0.752758</td>\n",
       "      <td>0.823267</td>\n",
       "      <td>0.574466</td>\n",
       "      <td>0.580843</td>\n",
       "      <td>0.769594</td>\n",
       "      <td>0.818143</td>\n",
       "      <td>0.914281</td>\n",
       "      <td>0.279528</td>\n",
       "      <td>6.957716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.935278</td>\n",
       "      <td>0.421235</td>\n",
       "      <td>0.303801</td>\n",
       "      <td>0.880214</td>\n",
       "      <td>0.665610</td>\n",
       "      <td>0.830131</td>\n",
       "      <td>0.487113</td>\n",
       "      <td>0.604157</td>\n",
       "      <td>0.874658</td>\n",
       "      <td>0.863427</td>\n",
       "      <td>0.983575</td>\n",
       "      <td>0.900464</td>\n",
       "      <td>0.935918</td>\n",
       "      <td>0.435772</td>\n",
       "      <td>7.951046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     cont1     cont2     cont3     cont4     cont5     cont6     cont7  \\\n",
       "0   1  0.670390  0.811300  0.643968  0.291791  0.284117  0.855953  0.890700   \n",
       "1   3  0.388053  0.621104  0.686102  0.501149  0.643790  0.449805  0.510824   \n",
       "2   4  0.834950  0.227436  0.301584  0.293408  0.606839  0.829175  0.506143   \n",
       "3   5  0.820708  0.160155  0.546887  0.726104  0.282444  0.785108  0.752758   \n",
       "4   8  0.935278  0.421235  0.303801  0.880214  0.665610  0.830131  0.487113   \n",
       "\n",
       "      cont8     cont9    cont10    cont11    cont12    cont13    cont14  \\\n",
       "0  0.285542  0.558245  0.779418  0.921832  0.866772  0.878733  0.305411   \n",
       "1  0.580748  0.418335  0.432632  0.439872  0.434971  0.369957  0.369484   \n",
       "2  0.558771  0.587603  0.823312  0.567007  0.677708  0.882938  0.303047   \n",
       "3  0.823267  0.574466  0.580843  0.769594  0.818143  0.914281  0.279528   \n",
       "4  0.604157  0.874658  0.863427  0.983575  0.900464  0.935918  0.435772   \n",
       "\n",
       "     target  \n",
       "0  7.243043  \n",
       "1  8.203331  \n",
       "2  7.776091  \n",
       "3  6.957716  \n",
       "4  7.951046  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [col for col in train.columns.to_list() if col not in ['id','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[columns]\n",
    "target=train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build our optimization function using optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function uses XgboostRegressor model, takes \n",
    "* the data\n",
    "* the target\n",
    "* trial(How many executions we will do) and return the  \n",
    "### and returns\n",
    "* RMSE(Root Mean Squared Rrror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "* Note that I used some XGBoostRegressor hyperparameters from Xgboost official site. \n",
    "* So if you like to add more parameters or change them, check this [link](https://xgboost.readthedocs.io/en/latest/parameter.html) \n",
    "* Also I used early_stopping_rounds to avoid overfiting\n",
    "* to speedup the training process enable the gpu or comment the first param argument(the training process will takes a lot of time by just using the cpu 😩) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial,data=data,target=target):\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15,random_state=42)\n",
    "    param = {\n",
    "        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
    "        'n_estimators': 4000,\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17,20]),\n",
    "        'random_state': trial.suggest_categorical('random_state', [24, 48,2020]),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgb.XGBRegressor(**param)  \n",
    "    \n",
    "    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n",
    "    \n",
    "    preds = model.predict(test_x)\n",
    "    \n",
    "    rmse = mean_squared_error(test_y, preds,squared=False)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All thing is ready So let's start 🏄‍\n",
    "* Note that the objective of our fuction is to minimize the RMSE that's why I set direction='minimize'\n",
    "* you can vary n_trials(number of executions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-17 22:26:06,273]\u001b[0m A new study created in memory with name: no-name-a556440d-afe7-46bd-b005-86e4eae66339\u001b[0m\n",
      "\u001b[32m[I 2021-01-17 22:27:18,217]\u001b[0m Trial 0 finished with value: 0.6945923734716385 and parameters: {'lambda': 0.0017177103549183793, 'alpha': 0.003988562114626481, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.009, 'max_depth': 9, 'random_state': 2020, 'min_child_weight': 253}. Best is trial 0 with value: 0.6945923734716385.\u001b[0m\n",
      "\u001b[32m[I 2021-01-17 22:29:12,446]\u001b[0m Trial 1 finished with value: 0.6940941378096152 and parameters: {'lambda': 0.002386980060622093, 'alpha': 0.057147467523410884, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.008, 'max_depth': 20, 'random_state': 2020, 'min_child_weight': 256}. Best is trial 1 with value: 0.6940941378096152.\u001b[0m\n",
      "\u001b[32m[I 2021-01-17 22:31:08,624]\u001b[0m Trial 2 finished with value: 0.6944582812854488 and parameters: {'lambda': 0.6206525538202995, 'alpha': 4.279277945699177, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.012, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 106}. Best is trial 1 with value: 0.6940941378096152.\u001b[0m\n",
      "\u001b[32m[I 2021-01-17 22:32:09,705]\u001b[0m Trial 3 finished with value: 0.695348434488198 and parameters: {'lambda': 0.3324528229021124, 'alpha': 0.0020255917285724955, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.018, 'max_depth': 20, 'random_state': 2020, 'min_child_weight': 103}. Best is trial 1 with value: 0.6940941378096152.\u001b[0m\n",
      "\u001b[32m[I 2021-01-17 22:33:05,710]\u001b[0m Trial 4 finished with value: 0.6943029616079647 and parameters: {'lambda': 1.9094723330454146, 'alpha': 7.000064697454118, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.018, 'max_depth': 11, 'random_state': 48, 'min_child_weight': 135}. Best is trial 1 with value: 0.6940941378096152.\u001b[0m\n",
      "\u001b[32m[I 2021-01-17 22:33:56,340]\u001b[0m Trial 5 finished with value: 0.6938094440644419 and parameters: {'lambda': 0.03161959455465672, 'alpha': 0.001469043781438218, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.014, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 226}. Best is trial 5 with value: 0.6938094440644419.\u001b[0m\n",
      "\u001b[32m[I 2021-01-17 22:35:24,456]\u001b[0m Trial 6 finished with value: 0.6935693874586953 and parameters: {'lambda': 0.020828425173643018, 'alpha': 1.0202182550769767, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.01, 'max_depth': 9, 'random_state': 2020, 'min_child_weight': 160}. Best is trial 6 with value: 0.6935693874586953.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-38380686d47f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'minimize'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Number of finished trials:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best trial:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    379\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m         )\n\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             )\n\u001b[0;32m     72\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-f6361b1af448>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial, data, target)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    547\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    207\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1247\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0;32m   1248\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1250\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do some Quick Visualization for Hyperparameter Optimization Analysis\n",
    "### Optuna provides various visualization features in optuna.visualization to analyze optimization results visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_optimization_histor: shows the scores from all trials as well as the best score so far at each point.\n",
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_parallel_coordinate: interactively visualizes the hyperparameters and scores\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''plot_slice: shows the evolution of the search. You can see where in the hyperparameter space your search\n",
    "went and which parts of the space were explored more.'''\n",
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_contour: plots parameter interactions on an interactive chart. You can choose which hyperparameters you would like to explore.\n",
    "optuna.visualization.plot_contour(study, params=['alpha',\n",
    "                            #'max_depth',\n",
    "                            'lambda',\n",
    "                            'subsample',\n",
    "                            'learning_rate',\n",
    "                            'subsample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize parameter importances.\n",
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize empirical distribution function\n",
    "optuna.visualization.plot_edf(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create an XgboostRegressor model with the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_trial {'lambda': 0.0030282073258141168, 'alpha': 0.01563845128469084, 'colsample_bytree': 0.5,\n",
    "             'subsample': 0.7,'n_estimators': 4000, 'learning_rate': 0.01,'max_depth': 15,\n",
    "             'random_state': 2020, 'min_child_weight': 257,'tree_method':'gpu_hist'}\n",
    "\n",
    "\n",
    "# Best_trial = {'lambda': 9.930238209261285, 'alpha': 6.507845870211356, 'colsample_bytree': 0.5,\n",
    "# 'subsample': 0.6, 'learning_rate': 0.009, 'max_depth': 13,\n",
    "# 'random_state': 24, 'min_child_weight': 92}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros(test.shape[0])\n",
    "kf = KFold(n_splits=5,random_state=48,shuffle=True)\n",
    "rmse=[]  # list contains rmse for each fold\n",
    "n=0\n",
    "for trn_idx, test_idx in kf.split(train[columns],train['target']):\n",
    "    X_tr,X_val=train[columns].iloc[trn_idx],train[columns].iloc[test_idx]\n",
    "    y_tr,y_val=train['target'].iloc[trn_idx],train['target'].iloc[test_idx]\n",
    "    model = xgb.XGBRegressor(**Best_trial)\n",
    "    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n",
    "    preds+=model.predict(test[columns])/kf.n_splits\n",
    "    rmse.append(mean_squared_error(y_val, model.predict(X_val), squared=False))\n",
    "    print(n+1,rmse[n])\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['target']=preds\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soon... hyperparameter tuning using Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Please If you find this kernel helpful, upvote it to help others see it 😊 😋"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
